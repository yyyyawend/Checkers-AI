{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yyyyawend/Checkers-AI/blob/master/5_Multipletest_Data_Organization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NeKOlx2VQIU",
        "outputId": "48e338a1-61f2-484c-e494-c07b4ee934a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/My Drive/Life_Singularity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wSEdiwhiOV-"
      },
      "outputs": [],
      "source": [
        "!pip install PyRuSH\n",
        "!wget https://github.com/jianlins/PyRuSH/raw/master/conf/rush_rules.tsv -P conf\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use PyRush to split text into sentences\n",
        "from PyRuSH import RuSH\n",
        "rush = RuSH('conf/rush_rules.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsE5WX7geZvL",
        "outputId": "32db5866-3fc2-4bd2-f768-e2e5b9559318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iivxF9Oe7vZZ"
      },
      "outputs": [],
      "source": [
        "BRANCH=\"main\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAFNe8WNhxZN"
      },
      "outputs": [],
      "source": [
        "#restart the runtime after running this cell in order to use newly installed versions.\n",
        "!apt-get update && apt-get install -y libsndfile1 ffmpeg\n",
        "!pip install Cython\n",
        "!pip install nemo_toolkit['all']\n",
        "!apt-get install cuda-11-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG1nSPuBxXcC"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ericharper/apex.git\n",
        "!cd apex\n",
        "!git checkout nm_v1.13.0\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" --global-option=\"--fast_layer_norm\" --global-option=\"--distributed_adam\" --global-option=\"--deprecated_fused_adam\" /content/apex/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f9heCTAUx0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a55df41-7b11-47d9-9521-8a1a96a960ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[NeMo W 2022-12-27 04:34:10 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2022-12-27 04:34:11 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2022-12-27 04:34:13 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:299: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
            "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nemo.collections import nlp as nemo_nlp\n",
        "from nemo.utils.exp_manager import exp_manager\n",
        "\n",
        "import os\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from omegaconf import OmegaConf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task Description\n",
        "\n",
        "In this task, we will using the fine tuned NER model get the entity class of each token, and the relation between entity pairs by the fine tuned RE model. Then Organize NER and RE output to a sqlite database so that we can select and plot information need."
      ],
      "metadata": {
        "id": "v6YeRxi6aNdK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing Data\n"
      ],
      "metadata": {
        "id": "ltUDNky9mB0l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7j8XAntVQCl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "DATA_DIR = \"/content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/DATA_DIR/\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.join(DATA_DIR, 'NER'), exist_ok=True)\n",
        "NER_DATA_DIR = f'{DATA_DIR}/NER'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read raw data\n",
        "with open(\"/content/drive/MyDrive/Life_Singularity/DATADIR/Second file - Greater than 1000 Patients - Notevents.csv\", 'r') as f:\n",
        "    read_data = f.readlines()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Life_Singularity/DATADIR/Greater_than_1000 Patients-Notevents.txt\", 'r') as f:\n",
        "    read_data1 = f.readlines()\n",
        "\n",
        "data = read_data + read_data1"
      ],
      "metadata": {
        "id": "Vsn1BejHmL05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "JxMs--uOmPS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check patients have more than 3 admission\n",
        "import re\n",
        "line_pattern = re.compile(r\"(\\d*,\\d*,\\d*,\\d{4}-\\d{1,2}-\\d{1,2}.*)\")\n",
        "count = {}\n",
        "for i in range(len(data)):\n",
        "  if line_pattern.match(data[i]):\n",
        "    pid = data[i].split(\",\")[1]\n",
        "    if pid in count.keys():\n",
        "      count[pid] += 1\n",
        "    else:\n",
        "      count[pid] = 1\n",
        "\n",
        "pati_multiple_admi = []\n",
        "for k, v in count.items():\n",
        "  if v >= 3:\n",
        "   pati_multiple_admi.append(k)"
      ],
      "metadata": {
        "id": "UrRcZPp-mZ1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate patients by the first line of each patient\n",
        "data1 = ''.join(data)\n",
        "pattern = r\"(\\d*,\\d*,\\d*,\\d{4}-\\d{1,2}-\\d{1,2}.*)\" # 174,22532,167853,2151-08-04 ****\n",
        "input = re.split(pattern, data1)\n",
        "del input[0]               #del \"\" at the beginning"
      ],
      "metadata": {
        "id": "jCU1cRlimlC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Link first line and the remaining content of each patient\n",
        "pers = {}\n",
        "notes = []\n",
        "for i in range(0, len(input), 2):\n",
        "  pid = input[i].split(',')[1]\n",
        "  if pid in pati_multiple_admi:\n",
        "    if pid in pers.keys():\n",
        "      pers[pid].append(input[i] + input[i + 1])\n",
        "    else:\n",
        "      pers[pid] = [input[i] + input[i + 1]]\n",
        "    notes.append(input[i] + input[i + 1])\n",
        "numPer = len(pers)"
      ],
      "metadata": {
        "id": "LgZBOJ3EmnUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check patient with heart disease history:\n",
        "pati_with_chf = []\n",
        "for k,v in pers.items():\n",
        "  for note in v:\n",
        "    if len(re.findall(r'heart failure', note.lower())) > 0 or len(re.findall('chf', note.lower())) > 0:\n",
        "      pati_with_chf.append(k)"
      ],
      "metadata": {
        "id": "F4BBDeUkmqbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Link first line and the remaining content of each patient\n",
        "pers = {}\n",
        "notes = []\n",
        "for i in range(0, len(input), 2):\n",
        "  pid = input[i].split(',')[1]\n",
        "  if pid in pati_multiple_admi:\n",
        "    if pid in pers.keys():\n",
        "      pers[pid].append(input[i] + input[i + 1])\n",
        "    else:\n",
        "      pers[pid] = [input[i] + input[i + 1]]\n",
        "    notes.append(input[i] + input[i + 1])\n",
        "numPer = len(pers)"
      ],
      "metadata": {
        "id": "fZXM8lANnMIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean(sen):\n",
        "  \"\"\"\n",
        "    clean str:\n",
        "    1)remove unnecessary sign like '\\[\\*\\*', '\\*\\*\\]' \n",
        "    2)convert test_name-test_value to test_name test_value \n",
        "    3)seperate date or value with words \n",
        "    4)add units to values\n",
        "   \n",
        "    :param sen: string need to be cleaned\n",
        "    :return: cleaned string \n",
        "  \"\"\" \n",
        "  sen = sen.lower()    #convert all characters to lower case\n",
        " \n",
        "  #remove \"-\" between test name and test value. eg. 'creat-2.0' to 'creat 2.0'\n",
        "  sen = re.sub(r\"([^\\d]+)-(\\d+\\.{0,1}\\d{1,2})\", r\"\\1 \\2\", sen)  \n",
        "  sen = re.sub(r\"hco3-(\\d+\\.{0,1}\\d+)\", r\"hco3 \\1 mmol/l\", sen) \n",
        "  sen = re.sub(r\"co2-(\\d+\\.{0,1}\\d+)\", r\"co2 \\1\", sen)\n",
        "   \n",
        "  sen = re.sub(r\"na\\+\", r\"na\", sen)  #replace 'na+' with 'na'\n",
        "  sen = re.sub(r\"k\\+\", r\"k\", sen) #replace 'k+' with 'k'\n",
        "  sen = sen.replace(\"[**\", \" \") #remove [**\n",
        "  sen = sen.replace(\"**]\", \" \") #remove **]\n",
        "  sen = sen.replace(\"*\", \" \") #remove *\n",
        "\n",
        "  #add units after test value\n",
        "  sen = re.sub(r\"creat (\\d{0,1}\\.{0,1}\\d+)\", r\"creat \\1 mg/d\", sen) \n",
        "  sen = re.sub(r\"creatinine (\\d{0,1}\\.{0,1}\\d+)\", r\"creatinine \\1 mg/d\", sen)\n",
        "  sen = re.sub(r\"creatinine was (\\d{0,1}\\.{0,1}\\d+)\", r\"creatinine was \\1 mg/d\", sen)\n",
        "  sen = re.sub(r\"creatinine of (\\d{0,1}\\.{0,1}\\d+)\", r\"creatinine of \\1 mg/d\", sen)\n",
        "  sen = re.sub(r\"albumin (\\d+\\.{0,1}\\d+)\", r\"albumin \\1 g/d\", sen)\n",
        "  sen = re.sub(r\"totbili (\\d+\\.{0,1}\\d+)\", r\"totbili \\1 mg/d\", sen)\n",
        "  sen = re.sub(r\"tot bili (\\d+\\.{0,1}\\d+)\", r\"totbili \\1 mg/d\", sen)\n",
        "  sen = re.sub(r\"crp (\\d+\\.{0,1}\\d+)\", r\"crp \\1 mg/l\", sen)\n",
        "  sen = re.sub(r\"chloride (\\d+\\.{0,1}\\d+)\", r\"chloride \\1 mmol/l\", sen)\n",
        "  sen = re.sub(r\"cl (\\d+\\.{0,1}\\d+)\", r\"cl \\1 mmol/l\", sen)\n",
        "  sen = re.sub(r\"hemoglobin (\\d+\\.{0,1}\\d+)\", r\"hemoglobin \\1 g/d\", sen)\n",
        "  sen = re.sub(r\"hgb (\\d+\\.{0,1}\\d+)\", r\"hgb \\1 g/dl\", sen)\n",
        "  sen = re.sub(r\"lactate (\\d+\\.{0,1}\\d+)\", r\"lactate \\1 mg/d\", sen)\n",
        "  sen = re.sub(r\"ld(ldh) (\\d+\\.{0,1}\\d+)\", r\"ld(ldh) \\1 mg/d\", sen)\n",
        "  sen = re.sub(r\"mch (\\d+\\.{0,1}\\d+)\", r\"mch \\1 pg/cell\", sen)\n",
        "  sen = re.sub(r\"mchc (\\d+\\.{0,1}\\d+)\", r\"mchc \\1 g/d\", sen)\n",
        "  sen = re.sub(r\"phosphate (\\d+\\.{0,1}\\d+)\", r\"phosphate \\1 mg/d\", sen)\n",
        "  sen = re.sub(r\"phos (\\d+\\.{0,1}\\d+)\", r\"phos \\1 mg/d\", sen)\n",
        "  sen = re.sub(r\"potassium (\\d+\\.{0,1}\\d+)\", r\"potassium \\1 mmol/l\", sen)\n",
        "  sen = re.sub(r\"k (\\d+\\.{0,1}\\d+)\", r\"k \\1 mmol/l\", sen)\n",
        "  sen = re.sub(r\"sodium (\\d+\\.{0,1}\\d+)\", r\"sodium \\1 mmol/l\", sen)\n",
        "  sen = re.sub(r\"na (\\d+\\.{0,1}\\d+)\", r\"na \\1 mmol/l\", sen)\n",
        "  sen = re.sub(r\"urean (\\d+\\.{0,1}\\d+)\", r\"urean \\1 mg/d\", sen)\n",
        "  sen = re.sub(r\"urea n (\\d+\\.{0,1}\\d+)\", r\"urean \\1 mg/d\", sen)\n",
        "  sen = re.sub(r\"bun (\\d+\\.{0,1}\\d+)\", r\"bun \\1 mg/d\", sen)\n",
        "  \n",
        "  #split date and words. \n",
        "  sen = re.sub(r\"(\\d{4}-\\d{1,2}-\\d{1,2})(.)\", r\"\\1 \\2\", sen)    #eg. '2102-1-2lab' to '2102-1-2 lab'\n",
        "  sen = re.sub(r\" ((0[1-9]|[1-9][^0-9]|1[0-2])-(0[1-9]|[1-9][^0-9]|1[0-9]|2[0-9]|3[0-1]))([^0-9].)\", r\" \\1 \\4\", sen) #eg. '1-2lab' to '1-2 lab'\n",
        "\n",
        "  sen = re.sub(r\"(\\d+[^,-]\\.\\d{1,2})([a-z]+)\", r\"\\1 \\2\", sen)  #split value and words. eg. '1.3creat' to '1.3 creat'\n",
        "  sen = re.sub(r\"([f | m])service\", r\"\\1 service\", sen) #add space betwee 'sex : f' and 'service'\n",
        "  sen = sen.replace(\"\\n\", \" \") #remove \"\\n\"\n",
        "  sen = re.sub('\\,\\,+', ',', sen) #replace repeated ',' with one ','\n",
        "  sen = ' '.join(sen.split())  # replace multiple spaces with a single space\n",
        "  return sen"
      ],
      "metadata": {
        "id": "D_Px4cRgnZTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_data = []\n",
        "for i in range(len(notes)):\n",
        "  # split text to sentences\n",
        "  per_sen = []\n",
        "  sentences = rush.segToSentenceSpans(notes[i])\n",
        "  for sen in sentences:\n",
        "      temp = notes[i][sen.begin:sen.end]\n",
        "      temp = clean(temp)\n",
        "      \n",
        "      temp = word_tokenize(temp)  # tokenize words\n",
        "      temp = \" \".join(temp)\n",
        "    \n",
        "      for line in temp.split(\"newline\"):\n",
        "        if len(line) > 480:\n",
        "         line = line[:480]\n",
        "        per_sen.append(line)\n",
        "  process_data.append(per_sen)"
      ],
      "metadata": {
        "id": "7uYSYNYhnpC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J8spPnYFjJu"
      },
      "source": [
        "# Implemet Database sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltPifnfWGWwA"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        " \n",
        "conn = sqlite3.connect('/content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/result.db')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NAKuK6hR8Kn"
      },
      "outputs": [],
      "source": [
        "#create tables, uncomment lines below if you want to create a new database\n",
        "# conn.execute('''\n",
        "# CREATE TABLE Patient(\n",
        "#    patient_id Integer PRIMARY KEY,\n",
        "#    subject_id varchar(20) UNIQUE,\n",
        "#    date_of_birth varchar(20),\n",
        "#    gender varchar(20)\n",
        "#  );''')\n",
        "\n",
        "# conn.execute('''\n",
        "# CREATE TABLE Admission(\n",
        "#    admission_id Integer PRIMARY KEY,\n",
        "#    Hadm varchar(20),\n",
        "#    admission_date varchar(20),\n",
        "#    discharge_date varchar(20),\n",
        "#    chf_diagnosis int\n",
        "#  );''')\n",
        "\n",
        "# conn.execute(''' CREATE TABLE Patient_Admission(\n",
        "#    admission_id int,\n",
        "#    patient_id int,\n",
        "#    CONSTRAINT fk_admission_id FOREIGN KEY(admission_id) REFERENCES ADMISSION(admission_id),\n",
        "#    CONSTRAINT fk_patient_id FOREIGN KEY(patient_id) REFERENCES Patient(patient_id)\n",
        "#  ); ''')\n",
        "\n",
        "# conn.execute('''CREATE TABLE Test(\n",
        "#    test_id Integer PRIMARY KEY AUTOINCREMENT,\n",
        "#    test_date varchar(50),\n",
        "#    test_time varchar(20),\n",
        "#    test_value varchart(20),\n",
        "#    test_type varchar(50)); ''')\n",
        "\n",
        "# conn.execute('''CREATE TABLE Admission_Test(\n",
        "#    admission_id int,\n",
        "#    test_id int,\n",
        "#    PRIMARY KEY (admission_id, test_id),\n",
        "#    CONSTRAINT fk_admission_id FOREIGN KEY(admission_id) REFERENCES ADMISSION(admission_id),\n",
        "#    CONSTRAINT fk_test_id FOREIGN KEY(test_id) REFERENCES TEST(test_id)\n",
        "#  );''')\n",
        "\n",
        "# conn.commit()\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05HrGe_VUgh5"
      },
      "source": [
        "# Obtained And Process NER Output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84b455a6"
      },
      "source": [
        "**NER Model configuration**\n",
        "\n",
        "Our Named Entity Recognition model is comprised of the pretrained [BERT](https://arxiv.org/pdf/1810.04805.pdf) model followed by a Token Classification layer.\n",
        "\n",
        "The model is defined in a config file which declares multiple important sections. They are:\n",
        "- **model**: All arguments that are related to the Model - language model, token classifier, optimizer and schedulers, datasets and any other related information\n",
        "\n",
        "- **trainer**: Any argument to be passed to PyTorch Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4fk3t0uUYXY"
      },
      "outputs": [],
      "source": [
        "NER_MODEL_CONFIG = \"token_classification_config.yaml\"\n",
        "NER_WORK_DIR = \"/content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/WORK_DIR\"\n",
        "os.makedirs(NER_WORK_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR2PMyEg7Frp",
        "outputId": "f603a02c-554f-44b7-8e24-ca834939a501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config file is already exists\n"
          ]
        }
      ],
      "source": [
        "# download the model's configuration file \n",
        "NER_config_dir = NER_WORK_DIR + '/configs/'\n",
        "os.makedirs(NER_config_dir, exist_ok=True)\n",
        "if not os.path.exists(NER_config_dir + NER_MODEL_CONFIG):\n",
        "    print('Downloading config file...')\n",
        "    wget.download(f'https://raw.githubusercontent.com/NVIDIA/NeMo/{BRANCH}/examples/nlp/token_classification/conf/' + NER_MODEL_CONFIG, NER_config_dir)\n",
        "else:\n",
        "    print ('config file is already exists')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-BPJasx7L8l",
        "outputId": "924b7bf3-7fb2-4820-8b87-65e6538a5c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/WORK_DIR/configs/token_classification_config.yaml\n"
          ]
        }
      ],
      "source": [
        "# this line will print the entire config of the model\n",
        "NER_config_path = f'{NER_WORK_DIR}/configs/{NER_MODEL_CONFIG}'\n",
        "print(NER_config_path)\n",
        "NER_config = OmegaConf.load(NER_config_path)\n",
        "# Note: these are small batch-sizes - increase as appropriate to available GPU capacity\n",
        "NER_config.model.train_ds.batch_size=20\n",
        "NER_config.model.validation_ds.batch_size=20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egb_0tAHJLq3"
      },
      "outputs": [],
      "source": [
        "print(OmegaConf.to_yaml(NER_config))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dedicated-effort"
      },
      "source": [
        "**NER Model Training**\n",
        "\n",
        "Setting up Data within the config\n",
        "\n",
        "Among other things, the config file contains dictionaries called dataset, train_ds and validation_ds. These are configurations used to setup the Dataset and DataLoaders of the corresponding config.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15e2c67a"
      },
      "source": [
        "\n",
        "We assume that both training and evaluation files are located in the same directory, and use the default names mentioned during the data download step. \n",
        "So, to start model training, we simply need to specify `model.dataset.data_dir`, like we are going to do below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89dd468d"
      },
      "source": [
        "\n",
        "Also notice that some config lines, including `model.dataset.data_dir`, have `???` in place of paths, this means that values for these fields are required to be specified by the user.\n",
        "\n",
        "Let's now add the data directory path to the config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a312ed76"
      },
      "outputs": [],
      "source": [
        "# in this tutorial train and dev datasets are located in the same folder, so it is enought to add the path of the data directory to the config\n",
        "NER_config.model.dataset.data_dir = NER_DATA_DIR\n",
        "NER_config.model.dataset.max_seq_length = 256\n",
        "\n",
        "# if you want to decrease the size of your datasets, uncomment the lines below:\n",
        "# NUM_SAMPLES = 100000\n",
        "# config.model.train_ds.num_samples = NUM_SAMPLES\n",
        "# config.model.validation_ds.num_samples = NUM_SAMPLES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "changed-mauritius"
      },
      "source": [
        "**Building the PyTorch Lightning Trainer**\n",
        "\n",
        "NeMo models are primarily PyTorch Lightning modules - and therefore are entirely compatible with the PyTorch Lightning ecosystem.\n",
        "\n",
        "Let's first instantiate a Trainer object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "computational-battlefield",
        "outputId": "03578cf0-3300-4efa-8f21-da6979e4cac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer config - \n",
            "\n",
            "devices: 1\n",
            "num_nodes: 1\n",
            "max_epochs: 5\n",
            "max_steps: -1\n",
            "accumulate_grad_batches: 1\n",
            "gradient_clip_val: 0.0\n",
            "precision: 16\n",
            "accelerator: gpu\n",
            "enable_checkpointing: false\n",
            "logger: false\n",
            "log_every_n_steps: 1\n",
            "val_check_interval: 1.0\n",
            "resume_from_checkpoint: null\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Trainer config - \\n\")\n",
        "print(OmegaConf.to_yaml(NER_config.trainer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unique-genre",
        "outputId": "98db4577-8657-48c4-aa35-8187c6835633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
          ]
        }
      ],
      "source": [
        "# lets modify some trainer configs\n",
        "# checks if we have GPU available and uses it\n",
        "accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
        "NER_config.trainer.devices = 1\n",
        "NER_config.trainer.accelerator = accelerator\n",
        "NER_config.trainer.max_epochs = 3\n",
        "NER_config.trainer.max_steps = -1\n",
        "# for PyTorch Native AMP set precision=16\n",
        "NER_config.trainer.precision = 16 if torch.cuda.is_available() else 32\n",
        "\n",
        "# remove distributed training flags\n",
        "NER_config.trainer.strategy = None\n",
        "\n",
        "NER_trainer = pl.Trainer(**NER_config.trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "overall-literature"
      },
      "source": [
        "**Setting up a NeMo Experiment**\n",
        "\n",
        "NeMo has an experiment manager that handles logging and checkpointing for us, so let's use it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "mathematical-portable",
        "outputId": "07f63696-d4c5-45d9-d28e-2ddfc21fa093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:37:33 exp_manager:291] Experiments will be logged at /content/nemo_experiments/token_classification_model/2022-12-03_16-37-33\n",
            "[NeMo I 2022-12-03 16:37:33 exp_manager:669] TensorboardLogger has been set up\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2022-12-03 16:37:33 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:2274: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\n",
            "      rank_zero_deprecation(\"`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\")\n",
            "    \n",
            "[NeMo W 2022-12-03 16:37:33 exp_manager:919] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/nemo_experiments/token_classification_model/2022-12-03_16-37-33'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "NER_exp_dir = exp_manager(NER_trainer, NER_config.get(\"exp_manager\", None))\n",
        "os.makedirs(NER_WORK_DIR, exist_ok=True)\n",
        "\n",
        "# the exp_dir provides a path to the current experiment for easy access\n",
        "NER_exp_dir = str(NER_exp_dir)\n",
        "NER_exp_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f62ea6cd"
      },
      "source": [
        "To load the pretrained BERT LM model, we can get the list of names by following command "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6b2ea1a",
        "outputId": "b9908977-f1a6-4283-d0b9-8c91c1cd83bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['megatron_bert_345m_cased', 'megatron_bert_345m_uncased', 'biomegatron345m_biovocab_50k_cased', 'biomegatron345m_biovocab_50k_uncased', 'biomegatron345m_biovocab_30k_cased', 'biomegatron345m_biovocab_30k_uncased', 'biomegatron-bert-345m-cased', 'biomegatron-bert-345m-uncased']\n"
          ]
        }
      ],
      "source": [
        "from nemo.collections.nlp.models.language_modeling.megatron_bert_model import MegatronBertModel\n",
        "print([model.pretrained_model_name for model in MegatronBertModel.list_available_models()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "compact-horse"
      },
      "outputs": [],
      "source": [
        "# add the specified above model parameters to the config\n",
        "# config.model.language_model.pretrained_model_name = PRETRAINED_BERT_MODEL\n",
        "NER_config.model.language_model.lm_checkpoint = None\n",
        "NER_config.model.language_model.pretrained_model_name = 'biomegatron345m_biovocab_30k_cased'\n",
        "NER_config.model.tokenizer.tokenizer_name = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3e14ed604a7d451eaa84d93490714d48",
            "44c2b1b2c28f4adb9612cd7aa162deae",
            "e9ab783e9dac48aea6494039aba1d1f6",
            "22d1437e79f647719c32bc20620bae21",
            "4294125876c34de7a975063ede43b334",
            "30c820fe21ff4dfd94700f029c057e2b",
            "58f9e5fcea064ece81176cce3a01c521",
            "3f1f5c5977e74b599e8d93f99107ad13",
            "f984aa9b6c5d4dc7b711d91aae8210e4",
            "0648638aa5824691adc72e02abc6e7c0",
            "dd1c006629e740549ba4b29ec2999787",
            "0e7eece9614046bb83ab44b2b273ea03",
            "15c9c03d034943c2b3db6eb9a2449e6e",
            "f32692408dc54e36ad828fc784472727",
            "6fcb9931bc9a4f00838a9f588ef71d74",
            "e70261538a4a4a40b53301675db5dca9",
            "167eb2445b3545549e0d8174794501bf",
            "9d6f8a5a3f584f5fa345c55601f26942",
            "9701659c7fbe4926b7555f1ce8e3f992",
            "8a6c691ca3b64a25b8e02523a15641a1",
            "842d7c17cbf44e318de1892a95cb1630",
            "4995be44d5d64f1492db1ab01cc80a8e",
            "0c7369bbfca9432cb26e4269865bb191",
            "2235e001e0ac4d8bb9bd567b9504bb34",
            "011daf1d8530495ba631aee0853249f5",
            "3ef590576ef54d619409a170931cc913",
            "16a249faa1184e4591405f65252085a4",
            "83a1405c257548d5b24a10416947e58b",
            "90594ebbe06f4d79b637e036f4292866",
            "03a058692faf4594b810630a4a182465",
            "f9be4cc2d12241c88fcb6a0ab4b9a4f3",
            "a27b4fde20f74058ae70834d74036a37",
            "772e8d62661744858e98d2f6e981222b"
          ]
        },
        "id": "di0hGvCMT6A3",
        "outputId": "6f170975-31c7-4f92-99ae-e807dd4aadae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2022-12-03 16:37:52 lm_utils:80] biomegatron345m_biovocab_30k_cased is not in get_pretrained_lm_models_list(include_external=False), will be using AutoModel from HuggingFace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:37:52 cloud:66] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/biomegatron345m_biovocab_30k_cased/versions/1/files/BioMegatron345m-biovocab-30k-cased.nemo to /root/.cache/torch/NeMo/NeMo_1.12.0/BioMegatron345m-biovocab-30k-cased/5885010653185bba59bf489ff757bf09/BioMegatron345m-biovocab-30k-cased.nemo\n",
            "[NeMo I 2022-12-03 16:38:28 common:910] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:204] Rank 0 has data parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:207] All data parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:208] Ranks 0 has data parallel rank: 0\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:216] Rank 0 has model parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:217] All model parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:227] Rank 0 has tensor model parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:231] All tensor model parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:232] Rank 0 has tensor model parallel rank: 0\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:246] Rank 0 has pipeline model parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:258] Rank 0 has embedding group: [0]\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:264] All pipeline model parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:265] Rank 0 has pipeline model parallel rank 0\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:266] All embedding group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:38:38 megatron_init:267] Rank 0 has embedding rank: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2022-12-03 16:38:38 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:38:38 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-bert-345m-cased, custom vocab file: /tmp/tmpgd1unz0e/f67afcc805164750a9eb2aa564aaf9a9_pubmed_merged-all-cased.vocab.txt, and merges file: None\n",
            "[NeMo I 2022-12-03 16:38:38 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-large-cased, vocab_file: /tmp/tmpgd1unz0e/f67afcc805164750a9eb2aa564aaf9a9_pubmed_merged-all-cased.vocab.txt, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e14ed604a7d451eaa84d93490714d48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e7eece9614046bb83ab44b2b273ea03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c7369bbfca9432cb26e4269865bb191"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using eos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:38:41 megatron_base_model:185] Padded vocab_size: 31104, original vocab_size: 31079, dummy tokens: 25.\n",
            "[NeMo I 2022-12-03 16:38:42 save_restore_connector:243] Model MegatronBertModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.12.0/BioMegatron345m-biovocab-30k-cased/5885010653185bba59bf489ff757bf09/BioMegatron345m-biovocab-30k-cased.nemo.\n",
            "[NeMo I 2022-12-03 16:38:42 token_classification_utils:54] Processing /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/DATA_DIR/NER/labels_train.txt\n",
            "[NeMo I 2022-12-03 16:38:43 token_classification_utils:74] Using provided labels mapping {'O': 0, 'B_DOA': 1, 'B_DOB': 2, 'B_DOC': 3, 'B_Date': 4, 'B_Heart_Disease': 5, 'B_SEX': 6, 'B_Test_Name': 7, 'B_Time': 8, 'I_DOA': 9, 'I_DOB': 10, 'I_DOC': 11, 'I_Date': 12, 'I_Heart_Disease': 13, 'I_SEX': 14, 'I_Test_Name': 15, 'PER': 16, 'Test_Unit': 17, 'Test_Value': 18}\n",
            "[NeMo I 2022-12-03 16:38:43 token_classification_utils:90] Labels mapping {'O': 0, 'B_DOA': 1, 'B_DOB': 2, 'B_DOC': 3, 'B_Date': 4, 'B_Heart_Disease': 5, 'B_SEX': 6, 'B_Test_Name': 7, 'B_Time': 8, 'I_DOA': 9, 'I_DOB': 10, 'I_DOC': 11, 'I_Date': 12, 'I_Heart_Disease': 13, 'I_SEX': 14, 'I_Test_Name': 15, 'PER': 16, 'Test_Unit': 17, 'Test_Value': 18} saved to : /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/DATA_DIR/NER/nemo:e212526e7b8e48d6b17381a08d1efec4_label_ids.csv\n",
            "[NeMo I 2022-12-03 16:39:02 token_classification_utils:99] Three most popular labels in /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/DATA_DIR/NER/labels_train.txt:\n",
            "[NeMo I 2022-12-03 16:39:02 data_preprocessing:194] label: 0, 1436941 out of 1541054 (93.24%).\n",
            "[NeMo I 2022-12-03 16:39:02 data_preprocessing:194] label: 6, 19703 out of 1541054 (1.28%).\n",
            "[NeMo I 2022-12-03 16:39:02 data_preprocessing:194] label: 7, 19227 out of 1541054 (1.25%).\n",
            "[NeMo I 2022-12-03 16:39:02 token_classification_utils:101] Total labels: 1541054. Label frequencies - {0: 1436941, 6: 19703, 7: 19227, 18: 16731, 4: 15523, 17: 11360, 8: 6327, 12: 2660, 9: 2391, 11: 2346, 15: 1573, 14: 1238, 10: 1222, 16: 800, 1: 797, 3: 782, 2: 611, 5: 411, 13: 411}\n",
            "[NeMo I 2022-12-03 16:39:02 token_classification_utils:107] Class weights restored from /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/DATA_DIR/NER/labels_train_weights.p\n",
            "[NeMo I 2022-12-03 16:39:11 token_classification_dataset:287] features restored from /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/DATA_DIR/NER/cached__text_train.txt__labels_train.txt__BertTokenizer_256_31079_-1\n",
            "[NeMo I 2022-12-03 16:39:11 token_classification_utils:54] Processing /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/DATA_DIR/NER/labels_dev.txt\n",
            "[NeMo I 2022-12-03 16:39:12 token_classification_utils:74] Using provided labels mapping {'O': 0, 'B_DOA': 1, 'B_DOB': 2, 'B_DOC': 3, 'B_Date': 4, 'B_Heart_Disease': 5, 'B_SEX': 6, 'B_Test_Name': 7, 'B_Time': 8, 'I_DOA': 9, 'I_DOB': 10, 'I_DOC': 11, 'I_Date': 12, 'I_Heart_Disease': 13, 'I_SEX': 14, 'I_Test_Name': 15, 'PER': 16, 'Test_Unit': 17, 'Test_Value': 18}\n",
            "[NeMo I 2022-12-03 16:39:12 token_classification_utils:96] /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/DATA_DIR/NER/labels_dev_label_stats.tsv found, skipping stats calculation.\n",
            "[NeMo I 2022-12-03 16:39:14 token_classification_dataset:287] features restored from /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/DATA_DIR/NER/cached__text_dev.txt__labels_dev.txt__BertTokenizer_256_31079_-1\n",
            "[NeMo I 2022-12-03 16:39:14 token_classification_utils:54] Processing /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/DATA_DIR/NER/labels_dev.txt\n",
            "[NeMo I 2022-12-03 16:39:14 token_classification_utils:74] Using provided labels mapping {'O': 0, 'B_DOA': 1, 'B_DOB': 2, 'B_DOC': 3, 'B_Date': 4, 'B_Heart_Disease': 5, 'B_SEX': 6, 'B_Test_Name': 7, 'B_Time': 8, 'I_DOA': 9, 'I_DOB': 10, 'I_DOC': 11, 'I_Date': 12, 'I_Heart_Disease': 13, 'I_SEX': 14, 'I_Test_Name': 15, 'PER': 16, 'Test_Unit': 17, 'Test_Value': 18}\n",
            "[NeMo I 2022-12-03 16:39:14 token_classification_utils:96] /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/DATA_DIR/NER/labels_dev_label_stats.tsv found, skipping stats calculation.\n",
            "[NeMo I 2022-12-03 16:39:16 token_classification_dataset:287] features restored from /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/NER/DATA_DIR/NER/cached__text_dev.txt__labels_dev.txt__BertTokenizer_256_31079_-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2022-12-03 16:39:16 lm_utils:80] biomegatron345m_biovocab_30k_cased is not in get_pretrained_lm_models_list(include_external=False), will be using AutoModel from HuggingFace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:39:16 cloud:56] Found existing object /root/.cache/torch/NeMo/NeMo_1.12.0/BioMegatron345m-biovocab-30k-cased/5885010653185bba59bf489ff757bf09/BioMegatron345m-biovocab-30k-cased.nemo.\n",
            "[NeMo I 2022-12-03 16:39:16 cloud:62] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.12.0/BioMegatron345m-biovocab-30k-cased/5885010653185bba59bf489ff757bf09/BioMegatron345m-biovocab-30k-cased.nemo\n",
            "[NeMo I 2022-12-03 16:39:16 common:910] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:204] Rank 0 has data parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:207] All data parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:208] Ranks 0 has data parallel rank: 0\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:216] Rank 0 has model parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:217] All model parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:227] Rank 0 has tensor model parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:231] All tensor model parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:232] Rank 0 has tensor model parallel rank: 0\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:246] Rank 0 has pipeline model parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:258] Rank 0 has embedding group: [0]\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:264] All pipeline model parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:265] Rank 0 has pipeline model parallel rank 0\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:266] All embedding group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:39:25 megatron_init:267] Rank 0 has embedding rank: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2022-12-03 16:39:25 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:39:25 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-bert-345m-cased, custom vocab file: /tmp/tmprav1h29z/f67afcc805164750a9eb2aa564aaf9a9_pubmed_merged-all-cased.vocab.txt, and merges file: None\n",
            "[NeMo I 2022-12-03 16:39:25 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-large-cased, vocab_file: /tmp/tmprav1h29z/f67afcc805164750a9eb2aa564aaf9a9_pubmed_merged-all-cased.vocab.txt, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using eos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:39:26 megatron_base_model:185] Padded vocab_size: 31104, original vocab_size: 31079, dummy tokens: 25.\n",
            "[NeMo I 2022-12-03 16:39:28 save_restore_connector:243] Model MegatronBertModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.12.0/BioMegatron345m-biovocab-30k-cased/5885010653185bba59bf489ff757bf09/BioMegatron345m-biovocab-30k-cased.nemo.\n",
            "[NeMo I 2022-12-03 16:39:28 nlp_model:174] Registering MegatronBERT model config for biomegatron345m_biovocab_30k_cased is not yet supported.                         Please override this method if needed.\n",
            "[NeMo I 2022-12-03 16:39:34 save_restore_connector:243] Model TokenClassificationModel was successfully restored from /content/drive/My Drive/Life_Singularity/Multiple_Test_Extraction/NER/MODEL/ner_model.nemo.\n"
          ]
        }
      ],
      "source": [
        "#restore NER model\n",
        "NER_model = nemo_nlp.models.TokenClassificationModel.restore_from(restore_path='/content/drive/My Drive/Life_Singularity/Multiple_Test_Extraction/NER/MODEL/ner_model.nemo', trainer = NER_trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v22-xUJ20KEF"
      },
      "outputs": [],
      "source": [
        "NER_model.half()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_whKCxfTMo6Y"
      },
      "source": [
        "# RE Model configuration\n",
        "\n",
        "Now, let's take a closer look at the model's configuration and learn to train the model.\n",
        "\n",
        "The model is defined in a config file which declares multiple important sections. They are:\n",
        "- **model**: All arguments that are related to the Model - language model, a classifier, optimizer and schedulers, datasets and any other related information\n",
        "\n",
        "- **trainer**: Any argument to be passed to PyTorch Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74FyWrQdPdVv"
      },
      "outputs": [],
      "source": [
        "TASK = 'ChemProt'\n",
        "RE_DATA_DIR = '/content/drive/MyDrive/Life_Singularity/RE'\n",
        "RE_WORK_DIR = '/content/drive/MyDrive/Life_Singularity/RE/WORK_DIR'\n",
        "RE_MODEL_CONFIG = 'text_classification_config.yaml'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79s89yCYO8pp",
        "outputId": "55cd6631-4191-41f3-9bfc-25658688f818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config file is already exists\n"
          ]
        }
      ],
      "source": [
        "# download the model's configuration file \n",
        "RE_MODEL_CONFIG = 'text_classification_config.yaml'\n",
        "RE_config_dir = RE_WORK_DIR + '/configs/'\n",
        "os.makedirs(RE_config_dir, exist_ok=True)\n",
        "if not os.path.exists(RE_config_dir + RE_MODEL_CONFIG):\n",
        "    print('Downloading config file...')\n",
        "    wget.download(f'https://raw.githubusercontent.com/NVIDIA/NeMo/{BRANCH}/examples/nlp/text_classification/conf/' + RE_MODEL_CONFIG, RE_config_dir)\n",
        "else:\n",
        "    print ('config file is already exists')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX3KmWMvSUQw",
        "outputId": "0265c8bf-a396-4276-faac-08cf7395c022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Life_Singularity/RE/WORK_DIR/configs/text_classification_config.yaml\n"
          ]
        }
      ],
      "source": [
        "# this line will print the entire config of the model\n",
        "RE_config_path = f'{RE_WORK_DIR}/configs/{RE_MODEL_CONFIG}'\n",
        "print(RE_config_path)\n",
        "RE_config = OmegaConf.load(RE_config_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79hWeuhhvTm_"
      },
      "outputs": [],
      "source": [
        "RE_config.model.train_ds.file_path = os.path.join(RE_DATA_DIR, 'train.tsv')\n",
        "RE_config.model.validation_ds.file_path = os.path.join(RE_DATA_DIR, 'dev.tsv')\n",
        "RE_config.model.task_name = 'chemprot'\n",
        "# Note: these are small batch-sizes - increase as appropriate to available GPU capacity\n",
        "RE_config.model.train_ds.batch_size=8\n",
        "RE_config.model.validation_ds.batch_size=8\n",
        "RE_config.model.dataset.num_classes=6\n",
        "RE_config.trainer.max_epochs=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLUU6Am8PZQU",
        "outputId": "5472fe4d-bb4a-4483-f375-66e978b271ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 3\n",
            "  max_steps: -1\n",
            "  accumulate_grad_batches: 1\n",
            "  gradient_clip_val: 0.0\n",
            "  precision: 32\n",
            "  accelerator: gpu\n",
            "  log_every_n_steps: 1\n",
            "  val_check_interval: 1.0\n",
            "  resume_from_checkpoint: null\n",
            "  num_sanity_val_steps: 0\n",
            "  enable_checkpointing: false\n",
            "  logger: false\n",
            "model:\n",
            "  nemo_path: text_classification_model.nemo\n",
            "  tokenizer:\n",
            "    tokenizer_name: ${model.language_model.pretrained_model_name}\n",
            "    vocab_file: null\n",
            "    tokenizer_model: null\n",
            "    special_tokens: null\n",
            "  language_model:\n",
            "    pretrained_model_name: bert-base-uncased\n",
            "    lm_checkpoint: null\n",
            "    config_file: null\n",
            "    config: null\n",
            "  classifier_head:\n",
            "    num_output_layers: 2\n",
            "    fc_dropout: 0.1\n",
            "  class_labels:\n",
            "    class_labels_file: null\n",
            "  dataset:\n",
            "    num_classes: 6\n",
            "    do_lower_case: false\n",
            "    max_seq_length: 256\n",
            "    class_balancing: null\n",
            "    use_cache: false\n",
            "  train_ds:\n",
            "    file_path: /content/drive/MyDrive/Life_Singularity/RE/train.tsv\n",
            "    batch_size: 8\n",
            "    shuffle: true\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "  validation_ds:\n",
            "    file_path: /content/drive/MyDrive/Life_Singularity/RE/dev.tsv\n",
            "    batch_size: 8\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "  test_ds:\n",
            "    file_path: null\n",
            "    batch_size: 64\n",
            "    shuffle: false\n",
            "    num_samples: -1\n",
            "    num_workers: 3\n",
            "    drop_last: false\n",
            "    pin_memory: false\n",
            "  optim:\n",
            "    name: adam\n",
            "    lr: 2.0e-05\n",
            "    betas:\n",
            "    - 0.9\n",
            "    - 0.999\n",
            "    weight_decay: 0.01\n",
            "    sched:\n",
            "      name: WarmupAnnealing\n",
            "      warmup_steps: null\n",
            "      warmup_ratio: 0.1\n",
            "      last_epoch: -1\n",
            "      monitor: val_loss\n",
            "      reduce_on_plateau: false\n",
            "  infer_samples:\n",
            "  - by the end of no such thing the audience , like beatrice , has a watchful affection\n",
            "    for the monster .\n",
            "  - director rob marshall went out gunning to make a great one .\n",
            "  - uneasy mishmash of styles and genres .\n",
            "  task_name: chemprot\n",
            "exp_manager:\n",
            "  exp_dir: null\n",
            "  name: TextClassification\n",
            "  create_tensorboard_logger: true\n",
            "  create_checkpoint_callback: true\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(OmegaConf.to_yaml(RE_config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQHCJN-ZaoLp"
      },
      "outputs": [],
      "source": [
        "RE_config.model.task_name = TASK\n",
        "RE_config.model.output_dir = RE_WORK_DIR\n",
        "RE_config.model.dataset.data_dir = RE_DATA_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kvqPwn2QFyP",
        "outputId": "ba504647-cbe0-4fd9-eed9-3935f635341b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer config - \n",
            "\n",
            "devices: 1\n",
            "num_nodes: 1\n",
            "max_epochs: 3\n",
            "max_steps: -1\n",
            "accumulate_grad_batches: 1\n",
            "gradient_clip_val: 0.0\n",
            "precision: 32\n",
            "accelerator: gpu\n",
            "log_every_n_steps: 1\n",
            "val_check_interval: 1.0\n",
            "resume_from_checkpoint: null\n",
            "num_sanity_val_steps: 0\n",
            "enable_checkpointing: false\n",
            "logger: false\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Trainer config - \\n\")\n",
        "print(OmegaConf.to_yaml(RE_config.trainer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knF6QeQQdMrH",
        "outputId": "54a23d2a-0532-433b-888b-2fcff67cc324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit native Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
          ]
        }
      ],
      "source": [
        "# lets modify some trainer configs\n",
        "# checks if we have GPU available and uses it\n",
        "RE_config.trainer.devices = 1\n",
        "RE_config.trainer.accelerator = accelerator\n",
        "\n",
        "# for PyTorch Native AMP set precision=16\n",
        "RE_config.trainer.precision = 16 if torch.cuda.is_available() else 32\n",
        "\n",
        "# remove distributed training flags\n",
        "RE_config.trainer.strategy = None\n",
        "\n",
        "RE_trainer = pl.Trainer(**RE_config.trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "40ef878b302c4b0da54d964305e09bef",
            "48cc207de4dc42bb94e1e5ba4555f015",
            "d7fe3d3b3c184d31a2f700df1017a47e",
            "51e6974015f24b9087a1b8c7af0214a0",
            "cd539a30e94541638b801f5079e23ff0",
            "70e33bbfbe2742f9b78a765cf164c169",
            "0dd67a973cd44dfe938080269af90263",
            "273a962ab766460cb1ed6bc842c1df8b",
            "9106a1f4a6234cbda1484c87e21a5747",
            "9991170c990a46148f0fc8fc4c6e353d",
            "fd2550c9bbe747bbbe929ca6c5cbeeab",
            "d5213f9fb7254fb8ab2e3eda87543c26",
            "a721ff9e51164a5980eb675fc7439b68",
            "abdf33dff71b46cfb8d9930e24428aa7",
            "37b2d88dee834ba48c34d2c94ce458dc",
            "fc63ef3df82c4de7bf6829db93a42637",
            "3ba782dd006947f4a3a4254301bfb3dc",
            "b3a931e56e504339b9ce0d80bf1c65a4",
            "bff81c292ac846f5b36af39e7971e93e",
            "b72c45b3652142a1aecefa2a8fb4bb42",
            "d50feb140fe248bc8af98641533d477c",
            "f49d1c6a27a74e6baf7267f915c83c30",
            "9ec1a3d90b1a41229f91f2a7b496f85a",
            "21c6f4213a4547ee96c59d40052d7bc9",
            "613161dd62c148d6beef612a739969fa",
            "283bfb69505541fbb2614d923902afd3",
            "9324c5b3a81d4cda9584f6d025f1c1b6",
            "2a2ec832305e4d0b8eed4fcf3dff980d",
            "4860282ccef3497088df2611c9329445",
            "f8985c704dc3496a933886928880f78a",
            "cfc6abd23cb74f1c82316400568af15a",
            "f610f6931d0547998e9ed3395fae1c44",
            "f1abb4a4c92f4514ad56aab20a21fe11"
          ]
        },
        "id": "NJAAskr88dZK",
        "outputId": "cbc0ea35-8058-4e07-b3fe-624769f5c209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2022-12-03 16:39:55 lm_utils:80] biomegatron345m_biovocab_30k_uncased is not in get_pretrained_lm_models_list(include_external=False), will be using AutoModel from HuggingFace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:39:55 cloud:66] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/biomegatron345m_biovocab_30k_uncased/versions/1/files/BioMegatron345m-biovocab-30k-uncased.nemo to /root/.cache/torch/NeMo/NeMo_1.12.0/BioMegatron345m-biovocab-30k-uncased/885893c2477bc7f57b6706bdd8225da0/BioMegatron345m-biovocab-30k-uncased.nemo\n",
            "[NeMo I 2022-12-03 16:40:23 common:910] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:204] Rank 0 has data parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:207] All data parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:208] Ranks 0 has data parallel rank: 0\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:216] Rank 0 has model parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:217] All model parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:227] Rank 0 has tensor model parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:231] All tensor model parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:232] Rank 0 has tensor model parallel rank: 0\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:246] Rank 0 has pipeline model parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:258] Rank 0 has embedding group: [0]\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:264] All pipeline model parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:265] Rank 0 has pipeline model parallel rank 0\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:266] All embedding group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:40:28 megatron_init:267] Rank 0 has embedding rank: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2022-12-03 16:40:28 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:40:28 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-bert-345m-uncased, custom vocab file: /tmp/tmpx8c3hbzn/efa836622369436fa6aa99a1b658adde_pubmed_merged-all-uncased.vocab.txt, and merges file: None\n",
            "[NeMo I 2022-12-03 16:40:28 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-large-uncased, vocab_file: /tmp/tmpx8c3hbzn/efa836622369436fa6aa99a1b658adde_pubmed_merged-all-uncased.vocab.txt, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40ef878b302c4b0da54d964305e09bef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5213f9fb7254fb8ab2e3eda87543c26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ec1a3d90b1a41229f91f2a7b496f85a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using eos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:40:31 megatron_base_model:185] Padded vocab_size: 31104, original vocab_size: 31077, dummy tokens: 27.\n",
            "[NeMo I 2022-12-03 16:40:33 save_restore_connector:243] Model MegatronBertModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.12.0/BioMegatron345m-biovocab-30k-uncased/885893c2477bc7f57b6706bdd8225da0/BioMegatron345m-biovocab-30k-uncased.nemo.\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:120] Read 13515 examples from /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/RE/DATA_DIR/RE/train.tsv.\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:238] *** Example ***\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:239] example 0: ['glucose', 'was', '201', ',', 'blood', 'urea', 'nitrogen', 'was', '15', ',', 'creatinine', 'was', 'Test_Value', 'Test_Unit', ',', 'sodium', 'was', '139', ',', 'potassium', 'of', '4.1', ',', 'chloride', 'was', '105', ',', 'and', 'bicarbonate', 'was', '27', '.']\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:240] subtokens: [CLS] glucose was 201 , blood urea nitrogen was 15 , creatinine was test [UNK] value test [UNK] unit , sodium was 139 , potassium of 4 . 1 , chloride was 105 , and bicarbonate was 27 . [SEP]\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:241] input_ids: 101 2038 194 613 4012 1014 9161 4877 194 1429 4012 7990 194 894 100 1545 894 100 3688 4012 3761 194 22784 4012 7325 125 373 2756 193 4012 7573 194 10454 4012 136 16213 194 3466 2756 102\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:244] label: 5\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:238] *** Example ***\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:239] example 1: ['2107-5-29', '01:35am', 'blood', 'glucose', '97', 'urean', '39', 'mg/d', 'creat', '1.8', 'mg/d', 'na', '142', 'mmol/l', 'k', 'Test_Value', 'mmol/l', 'cl', '110', 'Test_Unit', 'hco3', '21', 'mmol/l', 'angap', '15']\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:240] subtokens: [CLS] 210 ##7 - 5 - 29 01 : 35 ##am blood glucose 97 urea ##n 39 mg / d creat 1 . 8 mg / d na 142 mmol / l k test [UNK] value mmol / l cl 110 test [UNK] unit hco ##3 21 mmol / l ang ##ap 15 [SEP]\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:241] input_ids: 101 18911 31018 1990 376 1990 3460 23651 9232 3634 196 1014 2038 9268 9161 30984 5307 1074 10310 129 4621 193 2756 694 1074 10310 129 2845 24128 6126 10310 156 305 894 100 1545 6126 10310 156 334 11473 894 100 3688 22574 31011 3090 6126 10310 156 1611 308 1429 102\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-12-03 16:40:33 text_classification_dataset:244] label: 2\n",
            "[NeMo I 2022-12-03 16:40:56 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2022-12-03 16:40:56 data_preprocessing:406] Min: 8 |                  Max: 222 |                  Mean: 63.24957454679985 |                  Median: 59.0\n",
            "[NeMo I 2022-12-03 16:40:56 data_preprocessing:412] 75 percentile: 65.00\n",
            "[NeMo I 2022-12-03 16:40:56 data_preprocessing:413] 99 percentile: 219.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2022-12-03 16:40:58 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "      warnings.warn(_create_warning_msg(\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:120] Read 2260 examples from /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/RE/DATA_DIR/RE/dev.tsv.\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:238] *** Example ***\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:239] example 0: ['B_Date', 'B_Time', 'urine', 'osmolal', '276imaging', ':']\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:240] subtokens: [CLS] b [UNK] date b [UNK] time urine osmol ##al 27 ##6 ##imaging : [SEP]\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:241] input_ids: 101 135 100 4383 135 100 671 4785 21945 120 3466 31015 11330 9232 102\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:244] label: 3\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:238] *** Example ***\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:239] example 1: ['2123-1-14', '06:30am', 'blood', 'wbc', '5.0', 'B_Test_Name', 'Test_Value', 'hgb', '10.8', 'g/dl', 'hct', '31.0']\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:240] subtokens: [CLS] 212 ##3 - 1 - 14 0 ##6 : 30 ##am blood wbc 5 . 0 b [UNK] test [UNK] name test [UNK] value hg ##b 10 . 8 g / dl hct 31 . 0 [SEP]\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:241] input_ids: 101 28953 31011 1990 193 1990 1566 2552 31015 9232 1584 196 1014 20077 376 2756 2552 135 100 894 100 10437 894 100 1545 5205 30998 700 2756 694 159 10310 7048 12163 5142 2756 2552 102\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:242] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:243] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "[NeMo I 2022-12-03 16:40:58 text_classification_dataset:244] label: 0\n",
            "[NeMo I 2022-12-03 16:41:02 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
            "[NeMo I 2022-12-03 16:41:02 data_preprocessing:406] Min: 11 |                  Max: 153 |                  Mean: 68.3424778761062 |                  Median: 60.0\n",
            "[NeMo I 2022-12-03 16:41:02 data_preprocessing:412] 75 percentile: 66.00\n",
            "[NeMo I 2022-12-03 16:41:02 data_preprocessing:413] 99 percentile: 149.00\n",
            "[NeMo I 2022-12-03 16:41:03 text_classification_model:193] Dataloader config or file_path for the test is missing, so no data loader for test is created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2022-12-03 16:41:03 lm_utils:80] biomegatron345m_biovocab_30k_uncased is not in get_pretrained_lm_models_list(include_external=False), will be using AutoModel from HuggingFace.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:41:03 cloud:56] Found existing object /root/.cache/torch/NeMo/NeMo_1.12.0/BioMegatron345m-biovocab-30k-uncased/885893c2477bc7f57b6706bdd8225da0/BioMegatron345m-biovocab-30k-uncased.nemo.\n",
            "[NeMo I 2022-12-03 16:41:03 cloud:62] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.12.0/BioMegatron345m-biovocab-30k-uncased/885893c2477bc7f57b6706bdd8225da0/BioMegatron345m-biovocab-30k-uncased.nemo\n",
            "[NeMo I 2022-12-03 16:41:03 common:910] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:204] Rank 0 has data parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:207] All data parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:208] Ranks 0 has data parallel rank: 0\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:216] Rank 0 has model parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:217] All model parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:227] Rank 0 has tensor model parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:231] All tensor model parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:232] Rank 0 has tensor model parallel rank: 0\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:246] Rank 0 has pipeline model parallel group: [0]\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:258] Rank 0 has embedding group: [0]\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:264] All pipeline model parallel group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:265] Rank 0 has pipeline model parallel rank 0\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:266] All embedding group ranks: [[0]]\n",
            "[NeMo I 2022-12-03 16:41:10 megatron_init:267] Rank 0 has embedding rank: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2022-12-03 16:41:10 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:41:10 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-bert-345m-uncased, custom vocab file: /tmp/tmpd_p_jdyh/efa836622369436fa6aa99a1b658adde_pubmed_merged-all-uncased.vocab.txt, and merges file: None\n",
            "[NeMo I 2022-12-03 16:41:10 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-large-uncased, vocab_file: /tmp/tmpd_p_jdyh/efa836622369436fa6aa99a1b658adde_pubmed_merged-all-uncased.vocab.txt, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using eos_token, but it is not set yet.\n",
            "Using bos_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2022-12-03 16:41:12 megatron_base_model:185] Padded vocab_size: 31104, original vocab_size: 31077, dummy tokens: 27.\n",
            "[NeMo I 2022-12-03 16:41:13 save_restore_connector:243] Model MegatronBertModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.12.0/BioMegatron345m-biovocab-30k-uncased/885893c2477bc7f57b6706bdd8225da0/BioMegatron345m-biovocab-30k-uncased.nemo.\n",
            "[NeMo I 2022-12-03 16:41:13 nlp_model:174] Registering MegatronBERT model config for biomegatron345m_biovocab_30k_uncased is not yet supported.                         Please override this method if needed.\n",
            "[NeMo I 2022-12-03 16:41:20 save_restore_connector:243] Model TextClassificationModel was successfully restored from /content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/RE/MODEL/nemo_re.nemo.\n"
          ]
        }
      ],
      "source": [
        "RE_model = nemo_nlp.models.TextClassificationModel.restore_from(restore_path=os.path.join('/content/drive/MyDrive/Life_Singularity/Multiple_Test_Extraction/RE/MODEL', \"nemo_re.nemo\"), trainer = RE_trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3h0Ncd9cEIA",
        "outputId": "e790c6d8-d57f-4de4-b272-f33f4cb6925c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextClassificationModel(\n",
              "  (loss): CrossEntropyLoss()\n",
              "  (bert_model): MegatronBertModel(\n",
              "    (model): BertModel(\n",
              "      (language_model): TransformerLanguageModel(\n",
              "        (embedding): Embedding(\n",
              "          (word_embeddings): VocabParallelEmbedding()\n",
              "          (position_embeddings): Embedding(512, 1024)\n",
              "          (tokentype_embeddings): Embedding(2, 1024)\n",
              "          (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder): ParallelTransformer(\n",
              "          (layers): ModuleList(\n",
              "            (0): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (1): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (2): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (3): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (4): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (5): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (6): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (7): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (8): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (9): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (10): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (11): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (12): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (13): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (14): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (15): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (16): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (17): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (18): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (19): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (20): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (21): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (22): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "            (23): ParallelTransformerLayer(\n",
              "              (input_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (self_attention): ParallelAttention(\n",
              "                (query_key_value): ColumnLinear()\n",
              "                (core_attention): CoreAttention(\n",
              "                  (scale_mask_softmax): FusedScaleMaskSoftmax()\n",
              "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (dense): RowParallelLinear()\n",
              "              )\n",
              "              (post_attention_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): ParallelMLP(\n",
              "                (dense_h_to_4h): ColumnLinear()\n",
              "                (dense_4h_to_h): RowParallelLinear()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (final_layernorm): MixedFusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (pooler): Identity()\n",
              "      )\n",
              "      (lm_head): Identity()\n",
              "      (binary_head): Identity()\n",
              "    )\n",
              "  )\n",
              "  (classifier): SequenceClassifier(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (mlp): MultiLayerPerceptron(\n",
              "      (layer0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (layer2): Linear(in_features=1024, out_features=6, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (classification_report): ClassificationReport()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "RE_model.half()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJAD4Bl52XKf"
      },
      "source": [
        "# Organize NER and RE Output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axNSrdLY2XKq"
      },
      "outputs": [],
      "source": [
        "def merge(queries, labels, B_label, I_label):\n",
        "  '''\n",
        "     merge entity chunck in the queries list and labels list\n",
        "    eg. queries: ['her', 'creatinine', 'was', '1.7', 'on', 'discharge']\n",
        "        labels: [5, 7, 0, 18, 4, 14]\n",
        "        user merge() function to merge 'B_Date' and 'I_Date' inr the labels list and corresponding tokens in the queries list:\n",
        "        merged_queries: ['her', 'creatinine', 'was', '1.7', 'on discharge']\n",
        "        merged_labels: [5, 7, 0, 18, 4']\n",
        "   \n",
        "    :param queries: a list of tokens\n",
        "    :param labels:  a list of labels\n",
        "    :param B_label:the class number of B_label need to be merged \n",
        "    :param I_label:the class number of I_label need to be merged \n",
        "    :return: queries list and labels list after merge\n",
        "  '''\n",
        "  for idx in range(len(queries)-1):\n",
        "    if labels[idx] == B_label and labels[idx+1] == I_label:\n",
        "      queries[idx] = queries[idx] + \" \" + queries[idx+1]\n",
        "      if idx + 2 < len(queries) and labels[idx+2] == I_label:\n",
        "        queries[idx] = queries[idx] + \" \" + queries[idx+2]\n",
        "\n",
        "  for ele,l in zip(queries[:],labels[:]):\n",
        "    if l == I_label:\n",
        "      queries.remove(ele)\n",
        "      labels.remove(l)\n",
        "  return labels, queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-Y38R922XKq"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def calculateAge(birthday, admission_day):   \n",
        "  '''\n",
        "     calcute the age of one patient by his birthday and the admission_date\n",
        "   \n",
        "    :param birthday: date of birth, datetime\n",
        "    :param admission_day:  date of admission, datetime\n",
        "    :return: age\n",
        "  '''\n",
        "  born = datetime.strptime(birthday, \"%Y-%m-%d\")\n",
        "  admission = datetime.strptime(admission_day, \"%Y-%m-%d\")\n",
        "  print((admission.month, admission.day) < (born.month, born.day))\n",
        "  return admission.year - born.year - ((admission.month, admission.day) < (born.month, born.day))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6sPwiBZlNH2"
      },
      "outputs": [],
      "source": [
        "def insert(sql, table_name):\n",
        "  '''\n",
        "     insert one record to the database, and return the index of the new inserted record\n",
        "   \n",
        "    :param sql: ad string of sql insertion statement\n",
        "    :param table_name:  the table will be updated\n",
        "    :return: the index of the new inserted record\n",
        "  '''\n",
        "  conn.execute(sql);\n",
        "  cursor = conn.execute(f\"select seq from sqlite_sequence where name='{table_name}';\")\n",
        "  insert_id = cursor.fetchone()[0]\n",
        "  conn.commit()\n",
        "  return insert_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJc5HzOe7tTa"
      },
      "outputs": [],
      "source": [
        "def genSql(dict, table_name):\n",
        "  '''\n",
        "     generate sql insertion statement\n",
        "   \n",
        "    :param dict: a dictionary whose key is column names of the table and value is values need to be inserted\n",
        "    :param table_name:  the table will be updated\n",
        "    :return: sql insertion statement string\n",
        "  '''\n",
        "  string = f\"INSERT INTO {table_name} (\"\n",
        "  val_str = \"VALUES (\"\n",
        "  keys = list(dict.keys())\n",
        "  for key in keys:\n",
        "    string += f\"{key}, \"\n",
        "    if key == \"begin_offset\" or key == \"end_offset\":\n",
        "      val_str += f\"{dict[key]}, \"\n",
        "    else:\n",
        "      val_str += f\"'{dict[key]}', \"\n",
        "  string = string[:-2]+\")\"\n",
        "  val_str = val_str[:-2]+\")\"\n",
        "  return string + \" \" + val_str +\";\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtaWJxg6DP99"
      },
      "outputs": [],
      "source": [
        "def standardTestName(text):\n",
        "  '''\n",
        "     uniform all test name abbrevations to a standard test name\n",
        "   \n",
        "    :param text: the original test name ectracted from clinical note\n",
        "    :return: the standard test name\n",
        "  '''\n",
        "  stan_text_name = \"\"\n",
        "  if text in [\"cr\", \"creat\", \"creatinine\", \"crea\", \"crn\", \"ctn\", \"cre\", \"crt\", \"cnn\", \"crtn\"]:\n",
        "    stan_text_name = \"Creatinine\"\n",
        "  elif text in [\"alb\", \"albumin\"]:\n",
        "    stan_text_name = \"Albumin\"\n",
        "  elif text in [\"bicarbonate\", \"hco3\", \"bicarb\", \"total co2\"]:\n",
        "    stan_text_name = \"Bicarbonate\"\n",
        "  elif text in [\"totbili\", \"total Bilirubin\"]:\n",
        "    stan_text_name = \"Bilirubin, Total\"\n",
        "  elif text == \"crp\":\n",
        "    stan_text_name = \"C-Reactive Prot\"\n",
        "  elif text in [\"chloride\", \"cl\"]:\n",
        "    stan_text_name = \"Chloride\"\n",
        "  elif text in [\"hemoglobin\", \"hgb\"]:\n",
        "    stan_text_name = \"Hemoglobin\"\n",
        "  elif text in [\"hematocrit\", \"hct\"]:\n",
        "    stan_text_name = \"Hematocrit\"\n",
        "  elif text in [\"ld(ldh)\", \"ldh\", \"ld\", \"lactate\", \"lactate dehydrogenase\"]:\n",
        "    stan_text_name = \"Lactate Dehydro\"\n",
        "  elif text == \"mch\":\n",
        "     stan_text_name = \"MCH\"\n",
        "  elif text == \"mchc\":\n",
        "    stan_text_name = \"MCHC\"\n",
        "  elif text == \"mcv\":\n",
        "    stan_text_name = \"MCV\"\n",
        "  elif text in [\"plt ct\", \"plt count\", \"platelet count\"]:\n",
        "    stan_text_name = \"Platelet Count\"\n",
        "  elif text in [\"phosphate\", \"phos\"]:\n",
        "    stan_text_name = \"Phosphate\"\n",
        "  elif text in [\"k\", \"potassium\"]:\n",
        "    stan_text_name = \"Potassium\"\n",
        "  elif text == \"rdw\":\n",
        "    stan_text_name = \"RDW\"\n",
        "  elif text in [\"rbc\", \"red blood cells\"]:\n",
        "    stan_text_name = \"Red Blood Cells\"\n",
        "  elif text in [\"sodium\", \"na\"]:\n",
        "    stan_text_name = \"Sodium\"\n",
        "  elif text in [\"urean\", \"bun\", \"urea nitrogen\"]:\n",
        "    stan_text_name = \"Urea Nitrogen\"\n",
        "  return  stan_text_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uWpdK5ICqhS"
      },
      "outputs": [],
      "source": [
        "ner_Labels_mapping = {'O': 0, 'B_DOA': 1, 'B_DOB': 2, 'B_DOC': 3, 'B_Date': 4, 'B_Heart_Disease': 5, 'B_SEX': 6, 'B_Test_Name': 7, 'B_Time': 8, 'I_DOA': 9, 'I_DOB': 10, 'I_DOC': 11, 'I_Date': 12, 'I_Heart_Disease': 13, 'I_SEX': 14, 'I_Test_Name': 15, 'PER': 16, 'Test_Unit': 17, 'Test_Value': 18}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def organize((queries, all_preds, adm_id, admDate, discDate):\n",
        "  '''\n",
        "    store entity info and it relation to database\n",
        "   \n",
        "    :param queries: a list of tokens\n",
        "    :param all_preds: the prediced entity labels for tokens in the queries list by NER model\n",
        "    :param adm_id: the admission id of notes\n",
        "    :param adm_date: the admission date of notes\n",
        "    :param discDate: the discharge date of notes\n",
        "  '''\n",
        "  if len(tokens) > 2 and date_pattern.match(tokens[0]) and time_pattern.match(tokens[1]):\n",
        "    test_date = tokens[0]\n",
        "    test_time = tokens[1]\n",
        "    tests = []\n",
        "  for i, token in enumerate(tokens):\n",
        "    if i < len(tokens) - 1 and token in test_list:\n",
        "      test = token\n",
        "      value = tokens[i+1]\n",
        "      tests.append((test, value))\n",
        "    elif i < len(tokens) - 1 and tokens[i] == \"heart\" and tokens[i+1] == \"failure\":\n",
        "      chf_status = 1\n",
        "    elif tokens[i] == \"chf\":\n",
        "      chf_status = 1\n",
        "  if len(tests) > 0:\n",
        "    conn.execute(f\"INSERT OR IGNORE INTO Patient (subject_id, date_of_birth, gender) VALUES ('{pid}','{birthday}','{gender}');\")\n",
        "    insert_pid = conn.execute(f\"select patient_id from Patient where subject_id='{pid}';\").fetchone()[0]\n",
        "    insert_aid = insert(f\"INSERT OR IGNORE INTO Admission (Hadm, admission_date, discharge_date) VALUES ('{admId}', '{admission_date}', '{discharge_date}');\", \"Admission\")\n",
        "    conn.execute(f\"INSERT OR IGNORE INTO Patient_Admission (patient_id, admission_id) VALUES ({insert_pid}, {insert_aid});\")\n",
        "    conn.commit()\n",
        "    for t in tests:\n",
        "      test = t[0]\n",
        "      value = t[1]\n",
        "      stan_test_name = standardTestName(test)\n",
        "      test_id  = insert(f\"INSERT INTO Test (test_date, test_time, test_value, test_type) VALUES ('{test_date}', '{test_time}', '{value}', '{stan_test_name}');\", \"Test\")\n",
        "      conn.execute(f\"INSERT INTO Admission_Test(admission_id, test_id) VALUES ({insert_aid}, {test_id});\") \n",
        "  conn.execute(f\"UPDATE Admission SET chf_diagnosis = {chf_status} WHERE admission_id = '{insert_aid}'\")"
      ],
      "metadata": {
        "id": "kTZs4p3tmYCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4Y_eDB3mGpM"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import copy\n",
        "value_pattern = re.compile(r\"^(\\d+\\.{0,1}\\d{1,2})$\")\n",
        "\n",
        "def organize(queries, all_preds, adm_id, admDate, discDate):\n",
        "  '''\n",
        "    store entity info and it relation to database\n",
        "   \n",
        "    :param queries: a list of tokens\n",
        "    :param all_preds: the prediced entity labels for tokens in the queries list by NER model\n",
        "    :param adm_id: the admission id of notes\n",
        "    :param adm_date: the admission date of notes\n",
        "    :param discDate: the discharge date of notes\n",
        "  '''\n",
        "  start_idx, end_idx, BeginOffset, EndOffset = 0, 0, 0, 0\n",
        "  chf_status = 0\n",
        "  for query in queries:\n",
        "    end_idx += len(query)\n",
        "    preds = all_preds[start_idx:end_idx]\n",
        "    start_idx = end_idx\n",
        "    date_idx, test_idx, value_idx, time_idx, unit_idx, dig_idx = {}, {}, {}, {}, {}, {}\n",
        "    preds_merge, query_merge = merge(query, preds, 4, 12) #merge B_Date and I_Date\n",
        "    preds_merge, query_merge = merge(query, preds, 7, 15) #merge B_Test_Name and I_Test_Name\n",
        "    preds_merge, query_merge = merge(query, preds, 5, 13) #merge B_Heart_Disease and I_Heart_Disease\n",
        "    date_test_val = []\n",
        "    for j, word in enumerate(query_merge):\n",
        "      EndOffset = BeginOffset+len(word)\n",
        "      if preds_merge[j] == 4:\n",
        "          if \"admission\" in word:\n",
        "              date = admDate\n",
        "          elif \"discharge\" in word:\n",
        "              date = discDate\n",
        "          else:\n",
        "              date = word\n",
        "          date_idx[j] = {\"begin_offset\":BeginOffset, \"end_offset\":EndOffset, \"text\":word, \"date\":date, \"entity_type\":\"B_Date\"}\n",
        "      elif preds_merge[j] == 7:\n",
        "          stan_test_name = standardTestName(word)\n",
        "          if stan_test_name != '':\n",
        "            test_idx[j] = {\"begin_offset\":BeginOffset, \"end_offset\":EndOffset, \"text\":word, \"entity_type\":\"Test_Name\", \"test_type\": stan_test_name}\n",
        "      elif preds_merge[j] == 8:\n",
        "          time_idx[j] = {\"begin_offset\":BeginOffset, \"end_offset\":EndOffset, \"text\":word, \"entity_type\":\"B_Time\"}\n",
        "      elif preds_merge[j] == 18 and value_pattern.match(word):\n",
        "          value_idx[j] = {\"begin_offset\":BeginOffset, \"end_offset\":EndOffset, \"text\":word, \"entity_type\":\"Test_Value\"}\n",
        "      elif preds_merge[j] == 17:\n",
        "          unit_idx[j] = {\"begin_offset\":BeginOffset, \"end_offset\":EndOffset, \"text\":word, \"entity_type\":\"Test_Unit\"}\n",
        "      elif preds_merge[j] == 5:\n",
        "          chf_status = 1\n",
        "\n",
        "      BeginOffset = EndOffset + 1\n",
        "    BeginOffset += 1\n",
        "    \n",
        "    if len(date_idx) > 0 and len(test_idx) > 0 and len(value_idx) > 0:\n",
        "      for didx in date_idx.keys():\n",
        "        sen = copy.deepcopy(query_merge)\n",
        "        sen[didx] = \"B_Date\"\n",
        "        for tidx in test_idx.keys():\n",
        "          sen[tidx] = \"B_Test_Name\"\n",
        "          date_test_rel = RE_model.classifytext([\" \".join(sen)])\n",
        "          if date_test_rel[0] == 1:\n",
        "            sen[didx] = query_merge[didx]\n",
        "            for vidx in value_idx.keys():\n",
        "              sen[vidx] = \"Test_Value\"\n",
        "              test_val_rel = RE_model.classifytext([\" \".join(sen)])\n",
        "              if test_val_rel[0] == 0:\n",
        "                date_test_val.append([didx, tidx, vidx,-1])\n",
        "              sen[vidx] = query_merge[vidx]\n",
        "          sen[tidx] = query_merge[tidx]\n",
        "    \n",
        "    if len(date_test_val) > 0:\n",
        "      if len(time_idx) > 0:\n",
        "        for midx in time_idx.keys():\n",
        "          sen = copy.deepcopy(query_merge)\n",
        "          sen[midx] = \"B_Time\"\n",
        "          for i, idx in enumerate(date_test_val):\n",
        "            sen[idx[0]] = \"B_Date\"\n",
        "            date_time_rel = RE_model.classifytext([\" \".join(sen)])\n",
        "            if date_time_rel[0] == 3:\n",
        "              sen[idx[0]] = query_merge[idx[0]]\n",
        "              sen[idx[1]] = \"B_Test_Name\"\n",
        "              time_test_rel = RE_model.classifytext([\" \".join(sen)])\n",
        "              if time_test_rel[0] == 4:\n",
        "                date_test_val[i][3] = midx\n",
        "            sen[idx[0]] = query_merge[idx[0]]\n",
        "            sen[idx[1]] = query_merge[idx[1]]\n",
        "              \n",
        "      if len(unit_idx) > 0:\n",
        "        for uidx in unit_idx.keys():\n",
        "          sen = copy.deepcopy(query_merge)\n",
        "          sen[uidx] = \"Test_Unit\"\n",
        "          for i, idx in enumerate(date_test_val): \n",
        "            sen[idx[2]] = \"Test_Value\"\n",
        "            val_unit_rel = RE_model.classifytext([\" \".join(sen)])\n",
        "            if val_unit_rel[0] == 5:\n",
        "              date_test_val[i].append(uidx)\n",
        "            sen[idx[2]] = query_merge[idx[2]]\n",
        "          \n",
        "    for idx in date_test_val: \n",
        "      test_date = date_idx[idx[0]][\"date\"]\n",
        "      test_value = value_idx[idx[2]][\"text\"]\n",
        "      test_type = test_idx[idx[1]][\"test_type\"]\n",
        "      if idx[3] != -1:\n",
        "        test_time = time_idx[idx[3]][\"text\"]\n",
        "      else:\n",
        "        test_time = \"00:00AM\"\n",
        "      test_id  = insert(f\"INSERT INTO Test (test_date, test_time, test_value, test_type) VALUES ('{test_date}', '{test_time}', '{value}', '{test_type}');\", \"Test\")\n",
        "      conn.execute(f\"INSERT INTO Admission_Test(admission_id, test_id) VALUES ({adm_id}, {test_id});\") \n",
        "    conn.execute(f\"UPDATE Admission SET chf_diagnosis = {chf_status} WHERE admission_id = {adm_id}\")\n",
        "    conn.commit()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SCWYvSl2XKr"
      },
      "outputs": [],
      "source": [
        "per_pattern = re.compile(r\"(\\d*,\\d*,\\d*,\\d{4}-\\d{1,2}-\\d{1,2})\")\n",
        "date_pattern = re.compile(r\"\\d{4}-\\d{1,2}-\\d{1,2}\")\n",
        "\n",
        "for j,note in enumerate(process_data):\n",
        "  pid, admId, admission_date, discharge_date, birthday, gender= \"\", \"\",\"\",\"\",\"\",\"\"\n",
        "  line = (note[0]+\" \"+note[1]).split()\n",
        "  for i, token in enumerate(line):\n",
        "    if per_pattern.match(token):\n",
        "      (r, pid, admId, cd) = token.split(',')\n",
        "    elif token == \"admission\" and line[i+1] == \"date\" and line[i+2] == \":\":\n",
        "      if len(line) and date_pattern.match(line[i+3]):\n",
        "        admission_date = line[i+3]\n",
        "    elif token == \"discharge\" and line[i+1] == \"date\" and line[i+2] == \":\" and len(line) > i+3 and date_pattern.match(line[i+3]):\n",
        "      discharge_date = line[i+3]\n",
        "  birth = note[2].split()\n",
        "  if len(birth) > 3 and birth[2] == \"birth\" and date_pattern.match(birth[-1]):\n",
        "    birthday = birth[-1]\n",
        "  else:\n",
        "    birthday = \"Unknown\"\n",
        "  gen = note[3].split()\n",
        "  if gen[0] == \"sex\":\n",
        "    if gen[-1] == \"f\":\n",
        "      gender = \"Female\"\n",
        "    elif gen[-1] == \"m\":\n",
        "      gender = \"Male\"\n",
        "    else:\n",
        "      gender = \"Unknown\"\n",
        "  conn.execute(f\"INSERT OR IGNORE INTO Patient (subject_id, date_of_birth, gender) VALUES ('{pid}','{birthday}','{gender}');\")\n",
        "  insert_pid = conn.execute(f\"select patient_id from Patient where subject_id='{pid}';\").fetchone()[0]\n",
        "  conn.commit()\n",
        "  insert_aid = insert(f\"INSERT INTO Admission (Hadm, admission_date, discharge_date) VALUES ('{admId}', '{admission_date}', '{discharge_date}');\", \"Admission\")\n",
        "  conn.execute(f\"INSERT INTO Patient_Admission (patient_id, admission_id) VALUES ({insert_pid}, {insert_aid});\")\n",
        "  conn.commit()\n",
        "  all_preds = NER_model._infer(note, 1)\n",
        "  queries = [q.strip().split() for q in note]\n",
        "  organize(queries, all_preds, insert_aid, admission_date, discharge_date)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ltUDNky9mB0l",
        "-J8spPnYFjJu",
        "05HrGe_VUgh5",
        "_whKCxfTMo6Y"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e14ed604a7d451eaa84d93490714d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44c2b1b2c28f4adb9612cd7aa162deae",
              "IPY_MODEL_e9ab783e9dac48aea6494039aba1d1f6",
              "IPY_MODEL_22d1437e79f647719c32bc20620bae21"
            ],
            "layout": "IPY_MODEL_4294125876c34de7a975063ede43b334"
          }
        },
        "44c2b1b2c28f4adb9612cd7aa162deae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30c820fe21ff4dfd94700f029c057e2b",
            "placeholder": "​",
            "style": "IPY_MODEL_58f9e5fcea064ece81176cce3a01c521",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "e9ab783e9dac48aea6494039aba1d1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f1f5c5977e74b599e8d93f99107ad13",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f984aa9b6c5d4dc7b711d91aae8210e4",
            "value": 29
          }
        },
        "22d1437e79f647719c32bc20620bae21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0648638aa5824691adc72e02abc6e7c0",
            "placeholder": "​",
            "style": "IPY_MODEL_dd1c006629e740549ba4b29ec2999787",
            "value": " 29.0/29.0 [00:00&lt;00:00, 804B/s]"
          }
        },
        "4294125876c34de7a975063ede43b334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c820fe21ff4dfd94700f029c057e2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58f9e5fcea064ece81176cce3a01c521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f1f5c5977e74b599e8d93f99107ad13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f984aa9b6c5d4dc7b711d91aae8210e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0648638aa5824691adc72e02abc6e7c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd1c006629e740549ba4b29ec2999787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e7eece9614046bb83ab44b2b273ea03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15c9c03d034943c2b3db6eb9a2449e6e",
              "IPY_MODEL_f32692408dc54e36ad828fc784472727",
              "IPY_MODEL_6fcb9931bc9a4f00838a9f588ef71d74"
            ],
            "layout": "IPY_MODEL_e70261538a4a4a40b53301675db5dca9"
          }
        },
        "15c9c03d034943c2b3db6eb9a2449e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_167eb2445b3545549e0d8174794501bf",
            "placeholder": "​",
            "style": "IPY_MODEL_9d6f8a5a3f584f5fa345c55601f26942",
            "value": "Downloading config.json: 100%"
          }
        },
        "f32692408dc54e36ad828fc784472727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9701659c7fbe4926b7555f1ce8e3f992",
            "max": 762,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a6c691ca3b64a25b8e02523a15641a1",
            "value": 762
          }
        },
        "6fcb9931bc9a4f00838a9f588ef71d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_842d7c17cbf44e318de1892a95cb1630",
            "placeholder": "​",
            "style": "IPY_MODEL_4995be44d5d64f1492db1ab01cc80a8e",
            "value": " 762/762 [00:00&lt;00:00, 29.3kB/s]"
          }
        },
        "e70261538a4a4a40b53301675db5dca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "167eb2445b3545549e0d8174794501bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d6f8a5a3f584f5fa345c55601f26942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9701659c7fbe4926b7555f1ce8e3f992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6c691ca3b64a25b8e02523a15641a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "842d7c17cbf44e318de1892a95cb1630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4995be44d5d64f1492db1ab01cc80a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c7369bbfca9432cb26e4269865bb191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2235e001e0ac4d8bb9bd567b9504bb34",
              "IPY_MODEL_011daf1d8530495ba631aee0853249f5",
              "IPY_MODEL_3ef590576ef54d619409a170931cc913"
            ],
            "layout": "IPY_MODEL_16a249faa1184e4591405f65252085a4"
          }
        },
        "2235e001e0ac4d8bb9bd567b9504bb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83a1405c257548d5b24a10416947e58b",
            "placeholder": "​",
            "style": "IPY_MODEL_90594ebbe06f4d79b637e036f4292866",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "011daf1d8530495ba631aee0853249f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03a058692faf4594b810630a4a182465",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9be4cc2d12241c88fcb6a0ab4b9a4f3",
            "value": 213450
          }
        },
        "3ef590576ef54d619409a170931cc913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a27b4fde20f74058ae70834d74036a37",
            "placeholder": "​",
            "style": "IPY_MODEL_772e8d62661744858e98d2f6e981222b",
            "value": " 208k/208k [00:00&lt;00:00, 785kB/s]"
          }
        },
        "16a249faa1184e4591405f65252085a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a1405c257548d5b24a10416947e58b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90594ebbe06f4d79b637e036f4292866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03a058692faf4594b810630a4a182465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9be4cc2d12241c88fcb6a0ab4b9a4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a27b4fde20f74058ae70834d74036a37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "772e8d62661744858e98d2f6e981222b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40ef878b302c4b0da54d964305e09bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48cc207de4dc42bb94e1e5ba4555f015",
              "IPY_MODEL_d7fe3d3b3c184d31a2f700df1017a47e",
              "IPY_MODEL_51e6974015f24b9087a1b8c7af0214a0"
            ],
            "layout": "IPY_MODEL_cd539a30e94541638b801f5079e23ff0"
          }
        },
        "48cc207de4dc42bb94e1e5ba4555f015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e33bbfbe2742f9b78a765cf164c169",
            "placeholder": "​",
            "style": "IPY_MODEL_0dd67a973cd44dfe938080269af90263",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "d7fe3d3b3c184d31a2f700df1017a47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_273a962ab766460cb1ed6bc842c1df8b",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9106a1f4a6234cbda1484c87e21a5747",
            "value": 28
          }
        },
        "51e6974015f24b9087a1b8c7af0214a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9991170c990a46148f0fc8fc4c6e353d",
            "placeholder": "​",
            "style": "IPY_MODEL_fd2550c9bbe747bbbe929ca6c5cbeeab",
            "value": " 28.0/28.0 [00:00&lt;00:00, 980B/s]"
          }
        },
        "cd539a30e94541638b801f5079e23ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70e33bbfbe2742f9b78a765cf164c169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dd67a973cd44dfe938080269af90263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "273a962ab766460cb1ed6bc842c1df8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9106a1f4a6234cbda1484c87e21a5747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9991170c990a46148f0fc8fc4c6e353d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd2550c9bbe747bbbe929ca6c5cbeeab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5213f9fb7254fb8ab2e3eda87543c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a721ff9e51164a5980eb675fc7439b68",
              "IPY_MODEL_abdf33dff71b46cfb8d9930e24428aa7",
              "IPY_MODEL_37b2d88dee834ba48c34d2c94ce458dc"
            ],
            "layout": "IPY_MODEL_fc63ef3df82c4de7bf6829db93a42637"
          }
        },
        "a721ff9e51164a5980eb675fc7439b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ba782dd006947f4a3a4254301bfb3dc",
            "placeholder": "​",
            "style": "IPY_MODEL_b3a931e56e504339b9ce0d80bf1c65a4",
            "value": "Downloading config.json: 100%"
          }
        },
        "abdf33dff71b46cfb8d9930e24428aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bff81c292ac846f5b36af39e7971e93e",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b72c45b3652142a1aecefa2a8fb4bb42",
            "value": 571
          }
        },
        "37b2d88dee834ba48c34d2c94ce458dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d50feb140fe248bc8af98641533d477c",
            "placeholder": "​",
            "style": "IPY_MODEL_f49d1c6a27a74e6baf7267f915c83c30",
            "value": " 571/571 [00:00&lt;00:00, 23.6kB/s]"
          }
        },
        "fc63ef3df82c4de7bf6829db93a42637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ba782dd006947f4a3a4254301bfb3dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a931e56e504339b9ce0d80bf1c65a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bff81c292ac846f5b36af39e7971e93e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72c45b3652142a1aecefa2a8fb4bb42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d50feb140fe248bc8af98641533d477c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49d1c6a27a74e6baf7267f915c83c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ec1a3d90b1a41229f91f2a7b496f85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21c6f4213a4547ee96c59d40052d7bc9",
              "IPY_MODEL_613161dd62c148d6beef612a739969fa",
              "IPY_MODEL_283bfb69505541fbb2614d923902afd3"
            ],
            "layout": "IPY_MODEL_9324c5b3a81d4cda9584f6d025f1c1b6"
          }
        },
        "21c6f4213a4547ee96c59d40052d7bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a2ec832305e4d0b8eed4fcf3dff980d",
            "placeholder": "​",
            "style": "IPY_MODEL_4860282ccef3497088df2611c9329445",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "613161dd62c148d6beef612a739969fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8985c704dc3496a933886928880f78a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfc6abd23cb74f1c82316400568af15a",
            "value": 231508
          }
        },
        "283bfb69505541fbb2614d923902afd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f610f6931d0547998e9ed3395fae1c44",
            "placeholder": "​",
            "style": "IPY_MODEL_f1abb4a4c92f4514ad56aab20a21fe11",
            "value": " 226k/226k [00:00&lt;00:00, 890kB/s]"
          }
        },
        "9324c5b3a81d4cda9584f6d025f1c1b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a2ec832305e4d0b8eed4fcf3dff980d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4860282ccef3497088df2611c9329445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8985c704dc3496a933886928880f78a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfc6abd23cb74f1c82316400568af15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f610f6931d0547998e9ed3395fae1c44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1abb4a4c92f4514ad56aab20a21fe11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}